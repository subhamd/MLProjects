{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "3f7399cb-51b8-4819-97f8-3b6ff962737f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras  # install requirement, keras\n",
        "import keras  # import the keras library"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np  # import numpy library, numpy is a powerful N-dimensional array object. Read more at https://numpy.org\n",
        "\n",
        "# import the required Classes and methods from keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# import the mnist module\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "e442abf9-999b-4aa6-a82d-cb66dd07f375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# fetch mnist data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()  # X_train, X_test are array of image data and Y_train, y_test are array of category labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "6dff9735-99c9-42ae-d982-c755ec111cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "print (X_train.shape)  # print the dimension of X_train array (array of images to train with)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])  # display the 1st image in the training set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0dbb32fd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape the array of image data from NO_OF_IMAGESX28X28 to NO_OF_IMAGESX28X28X1\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "8e17e182-5257-4b98-8f51-7c7f096d77f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "7b711e88-ea3f-4b29-a9f0-dfbe010097ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4gaTGAW-qlw",
        "colab_type": "text"
      },
      "source": [
        "# First Model\n",
        "In the 1st approach, we architect a basic model with 3 blocks. In each block (except the last one) we gradually increase the number of kernels from 16 to 32 to 64 and between blocks try to use max pooling to reduce the no. of layers unless the max pooling layer is very near to the final layer. We are not using max pooling before the final layers because by doing so we might loose some important/trivial feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "a621387c-2280-4284-a900-6dd237e463d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "# The input channel dimension is 28X28X1, i.e., the input has 1 channel of size 28X28 pixels\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))  # 26\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))  # 24\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))  # 22\n",
        "\n",
        "model.add(MaxPooling2D(2))  # 11\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu'))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))  # 9\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))  # 7\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 5\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 3\n",
        "model.add(Convolution2D(10, 3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "ab81bd5e-e2ab-4e2e-c677-d03f999749e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 16)        1040      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 32)          4640      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          650       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 50,852\n",
            "Trainable params: 50,852\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "outputId": "5b1a6866-07b6-46e5-f230-02619c706f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "7f9d9346-4029-4b35-92e4-04359f70a1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model (with training data set), with batch size = 32, for 20 epochs\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 34s 568us/step - loss: 0.2465 - acc: 0.9237\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 27s 443us/step - loss: 0.0837 - acc: 0.9746\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 27s 442us/step - loss: 0.0643 - acc: 0.9804\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 27s 443us/step - loss: 0.0499 - acc: 0.9848\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.0445 - acc: 0.9862\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 28s 462us/step - loss: 0.0388 - acc: 0.9884\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.0344 - acc: 0.9895\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 0.0313 - acc: 0.9897\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0270 - acc: 0.9911\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 0.0249 - acc: 0.9920\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 28s 469us/step - loss: 0.0233 - acc: 0.9925\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0221 - acc: 0.9927\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0194 - acc: 0.9934\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0189 - acc: 0.9940\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.0175 - acc: 0.9944\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 28s 469us/step - loss: 0.0171 - acc: 0.9943\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 28s 466us/step - loss: 0.0161 - acc: 0.9951\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0154 - acc: 0.9951\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 0.0151 - acc: 0.9950\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.0146 - acc: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0db8a94fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "09a46183-6fa7-4487-ae6a-2a2dd359a5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluate the model with validation data set\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)  # Print the model accuracy on validation data set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05106720582045455, 0.989]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKQw4jPjFZyh",
        "colab_type": "text"
      },
      "source": [
        "### After running the model for 20 epochs, we see the following\n",
        "\n",
        "*   Training accuracy: 99.52%\n",
        "*   Validation accuracy: 98.9% **(we want this to be 99.4%)**\n",
        "\n",
        "### Also notice that the number of parameters is 50852, we want this number to be less than 20000. So let's try to fix that first in our next model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCn6kI2JjYk",
        "colab_type": "text"
      },
      "source": [
        "# Second Model\n",
        "\n",
        "In this approach, we use the same architecture as that of the previous one but try to avoid higher number of kernels in any layer so that the total number of parameters can be reduced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GHu0W4cJtzF",
        "colab_type": "code",
        "outputId": "bd194ec6-b079-48af-ed70-b83d6b8d1cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))  # 26\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 24\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))  # 22\n",
        "\n",
        "model.add(MaxPooling2D(2))  # 11\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu'))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 9\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 7\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 5\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 3\n",
        "model.add(Convolution2D(10, 3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HayNae43KF1q",
        "colab_type": "code",
        "outputId": "b1bd8267-3ccd-4881-8794-728b962e7333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 9, 9, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,188\n",
            "Trainable params: 15,188\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rViaun3qKLRJ",
        "colab_type": "text"
      },
      "source": [
        "### Well we were able to reach our goal of reducing the number of parameters to less than 20000. Now, let's train the model and check the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQP6FypsOmYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymbvHTwnK3w6",
        "colab_type": "code",
        "outputId": "f2f1922f-ba26-4f64-bdbc-3613f8532dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        }
      },
      "source": [
        "# Train the model (with training data set), with batch size = 32, for 20 epochs.\n",
        "# Also note that we are also checking the validation accuracy in each epoch. The result of this will not be added to back propagation \n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1, validation_data=(X_test, Y_test), )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "  448/60000 [..............................] - ETA: 24s - loss: 0.0207 - acc: 0.9911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0188 - acc: 0.9935 - val_loss: 0.0404 - val_acc: 0.9887\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0409 - val_acc: 0.9890\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0176 - acc: 0.9940 - val_loss: 0.0367 - val_acc: 0.9899\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0383 - val_acc: 0.9884\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0372 - val_acc: 0.9896\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0390 - val_acc: 0.9901\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0335 - val_acc: 0.9909\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0443 - val_acc: 0.9887\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 25s 408us/step - loss: 0.0145 - acc: 0.9955 - val_loss: 0.0501 - val_acc: 0.9877\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0151 - acc: 0.9948 - val_loss: 0.0406 - val_acc: 0.9896\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 25s 411us/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0424 - val_acc: 0.9876\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0344 - val_acc: 0.9912\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0429 - val_acc: 0.9886\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0447 - val_acc: 0.9889\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0434 - val_acc: 0.9896\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0406 - val_acc: 0.9889\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 25s 410us/step - loss: 0.0131 - acc: 0.9957 - val_loss: 0.0351 - val_acc: 0.9913\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0444 - val_acc: 0.9893\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0576 - val_acc: 0.9867\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 25s 410us/step - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0379 - val_acc: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d6c1c6d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDXDkZKsPoVy",
        "colab_type": "text"
      },
      "source": [
        "### After running the model for 20 epochs, we can see the following in Epoch# 12\n",
        "\n",
        "*   Training accuracy: 99.58%\n",
        "*   Validation accuracy: 99.12%\n",
        "\n",
        "### We still haven't reach our goal of 99.4% of validation accuracy under 20000 parameters. Let's try to fix this in our next model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7QJOobtQAYt",
        "colab_type": "text"
      },
      "source": [
        "# Third Model\n",
        "\n",
        "In this approach, we use the same model as that of the previous one and add Batch Normalization after every Convolution layer except the last one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gILQUYG1OWv_",
        "colab_type": "code",
        "outputId": "f510b749-1b63-422f-e07f-f017c15ffd9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))  # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))  # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(2))  # 11\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szpgi6v_Sr6m",
        "colab_type": "code",
        "outputId": "4be8fc38-fb3b-42dd-d783-8ea7e3f02eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 9, 9, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 3, 3, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,756\n",
            "Trainable params: 15,472\n",
            "Non-trainable params: 284\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATpRIpIFUlDl",
        "colab_type": "text"
      },
      "source": [
        "### Notice that by adding Batch Normalization we have increased the number of parameters by a little than the previous model, but we are still below 20000. \n",
        "\n",
        "### Also notice that Batch Normalization has introduced a new type of parameters, Non-trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK-6PHU9S11O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hM47VPjS7It",
        "colab_type": "code",
        "outputId": "ab9d3ca2-22b0-4f3f-af1d-9e8d5ca99c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "# Train the model (with training data set), with batch size = 32, for 20 epochs.\n",
        "# Also note that we are also checking the validation accuracy in each epoch. The result of this will not be added to back propagation \n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1, validation_data=(X_test, Y_test), )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 45s 750us/step - loss: 0.2562 - acc: 0.9220 - val_loss: 0.0671 - val_acc: 0.9775\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 43s 711us/step - loss: 0.0671 - acc: 0.9793 - val_loss: 0.0576 - val_acc: 0.9827\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.0510 - acc: 0.9843 - val_loss: 0.0449 - val_acc: 0.9860\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 43s 715us/step - loss: 0.0447 - acc: 0.9860 - val_loss: 0.0428 - val_acc: 0.9865\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.0382 - acc: 0.9880 - val_loss: 0.0619 - val_acc: 0.9823\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 42s 707us/step - loss: 0.0360 - acc: 0.9888 - val_loss: 0.0432 - val_acc: 0.9872\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 43s 711us/step - loss: 0.0314 - acc: 0.9895 - val_loss: 0.0342 - val_acc: 0.9899\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 43s 711us/step - loss: 0.0282 - acc: 0.9909 - val_loss: 0.0404 - val_acc: 0.9875\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 43s 723us/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0346 - val_acc: 0.9883\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.0255 - acc: 0.9920 - val_loss: 0.0349 - val_acc: 0.9896\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 43s 712us/step - loss: 0.0233 - acc: 0.9925 - val_loss: 0.0270 - val_acc: 0.9914\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 43s 711us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.0356 - val_acc: 0.9894\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 43s 712us/step - loss: 0.0214 - acc: 0.9929 - val_loss: 0.0341 - val_acc: 0.9909\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 43s 714us/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0320 - val_acc: 0.9911\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0347 - val_acc: 0.9911\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 43s 719us/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0314 - val_acc: 0.9912\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 43s 718us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.0329 - val_acc: 0.9900\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.0153 - acc: 0.9948 - val_loss: 0.0349 - val_acc: 0.9897\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0313 - val_acc: 0.9911\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.0132 - acc: 0.9955 - val_loss: 0.0324 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d5e498080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GavsIMvsT5eR",
        "colab_type": "text"
      },
      "source": [
        "### After running the model for 20 epochs, we can see the following in Epoch# 20\n",
        "\n",
        "*   Training accuracy: 99.55%\n",
        "*   Validation accuracy: 99.20%\n",
        "\n",
        "### Although we have added Batch Normalization we don't see a significant improvement over our previous model since we are using MNIST dataset, but there is some amount of improvement, although We are yet to reach our goal of 99.4% on validation accuracy.\n",
        "\n",
        "### Also if you notice, for most of epochs there is a good amount of difference between the training accuracy and validation accuracy E.g., `Epoch#17: 0.49%`, `Epoch#18: 0.51%`, `Epoch19: 0.44%`, etc., also the training accuracy is always higher than the validation accuracy. \n",
        "\n",
        "### It seems the model could be overfitting. Let's try to reduce the gap and also fix the issue of training accuracy being always higher than the validation accuracy in our next model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK4HzH33VyWQ",
        "colab_type": "text"
      },
      "source": [
        "# 4th Model\n",
        "\n",
        "In this approach, we use the same model as that of the previous one and add dropouts. Now we are not sure where to add dropouts, hence we add them after every convolution layer (except may be the last one) but with a very smaller value `0.1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahiNYDeMV7vn",
        "colab_type": "code",
        "outputId": "2b6dae0a-8980-4cf1-ff2e-097764419d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))  # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))  # 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(2))  # 11\n",
        "\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_62 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 9, 9, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 3, 3, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,756\n",
            "Trainable params: 15,472\n",
            "Non-trainable params: 284\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tZ76-ibbp1b",
        "colab_type": "text"
      },
      "source": [
        "### Notice that by adding dropouts we haven't changed the number of parameters and it is same as that of the previous model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oV8qzA5Xq86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icvZybjhYCCV",
        "colab_type": "code",
        "outputId": "94ae6a12-0a70-43b4-a344-9ec6984693f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "# Train the model (with training data set), with batch size = 32, for 15 epochs.\n",
        "# Also note that we are also checking the validation accuracy in each epoch. The result of this will not be added to back propagation \n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=15, verbose=1, validation_data=(X_test, Y_test), )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "  224/60000 [..............................] - ETA: 51s - loss: 0.0772 - acc: 0.9821"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 48s 801us/step - loss: 0.0378 - acc: 0.9883 - val_loss: 0.0237 - val_acc: 0.9929\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 48s 799us/step - loss: 0.0367 - acc: 0.9885 - val_loss: 0.0258 - val_acc: 0.9924\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 48s 799us/step - loss: 0.0354 - acc: 0.9894 - val_loss: 0.0261 - val_acc: 0.9921\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 48s 802us/step - loss: 0.0370 - acc: 0.9881 - val_loss: 0.0211 - val_acc: 0.9937\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 48s 808us/step - loss: 0.0336 - acc: 0.9897 - val_loss: 0.0232 - val_acc: 0.9922\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 48s 796us/step - loss: 0.0336 - acc: 0.9898 - val_loss: 0.0211 - val_acc: 0.9930\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 48s 803us/step - loss: 0.0326 - acc: 0.9900 - val_loss: 0.0244 - val_acc: 0.9928\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 48s 799us/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0204 - val_acc: 0.9938\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 48s 801us/step - loss: 0.0325 - acc: 0.9897 - val_loss: 0.0194 - val_acc: 0.9932\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 48s 804us/step - loss: 0.0332 - acc: 0.9891 - val_loss: 0.0208 - val_acc: 0.9928\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 49s 819us/step - loss: 0.0319 - acc: 0.9901 - val_loss: 0.0192 - val_acc: 0.9943\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 49s 820us/step - loss: 0.0309 - acc: 0.9899 - val_loss: 0.0192 - val_acc: 0.9944\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 50s 827us/step - loss: 0.0313 - acc: 0.9900 - val_loss: 0.0198 - val_acc: 0.9938\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 50s 835us/step - loss: 0.0296 - acc: 0.9905 - val_loss: 0.0219 - val_acc: 0.9927\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 50s 830us/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.0237 - val_acc: 0.9927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d5ce11828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30bwSJCNcC4x",
        "colab_type": "text"
      },
      "source": [
        "### After running the model for 15 epochs, We can clearly see that the 'overfitted model' discussed in the previous model is no more visible, i.e., there might still be some gap between training accuracy and validation accuracy but we have fixed the issue of 'training accuracy being always higher than the validation accuracy'\n",
        "\n",
        "### Also if you notice we have already reached our desired validation accuracy at `Epoch#11` and `Epoch#12`. But let's add smaller learning rates and see how that can also help in further improving the validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vXWSmNPdeyQ",
        "colab_type": "text"
      },
      "source": [
        "# 5th Model\n",
        "\n",
        "In this approach, we use the exact same model as that of the previous one but introduce smaller learning rates while training. Initially the learning rate will be set to `0.001`, which will gradually decrease"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymg-_SLBeiCo",
        "colab_type": "code",
        "outputId": "6b53ee21-6289-4d7d-8ebe-bfe5d86a65a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))  # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))  # 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(2))  # 11\n",
        "\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_72 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 9, 9, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 3, 3, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,756\n",
            "Trainable params: 15,472\n",
            "Non-trainable params: 284\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDM8U6c0d-H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.001 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO1-ZQFcezV1",
        "colab_type": "code",
        "outputId": "1a639d55-ea63-4e7b-ca2d-8368de3608e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=512, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0233 - val_acc: 0.9927\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0228 - acc: 0.9928 - val_loss: 0.0233 - val_acc: 0.9931\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0220 - val_acc: 0.9939\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0207 - val_acc: 0.9938\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0201 - val_acc: 0.9943\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0203 - val_acc: 0.9946\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0201 - val_acc: 0.9947\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0191 - val_acc: 0.9947\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0198 - val_acc: 0.9946\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0206 - val_acc: 0.9948\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0195 - val_acc: 0.9945\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0203 - val_acc: 0.9943\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0168 - acc: 0.9948 - val_loss: 0.0198 - val_acc: 0.9947\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 0.0195 - val_acc: 0.9949\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0193 - val_acc: 0.9948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d5b8e3080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMlr_QlqfKg7",
        "colab_type": "text"
      },
      "source": [
        "### After adding smaller learning rates we can see that we already reached our desired validation accuracy at `Epoch#5 itself` (and onwards). Also we can see that the gap between training and validation accuracy is quite negligible now in all the epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_voW4hQXsnQZ",
        "colab_type": "text"
      },
      "source": [
        "# 6th Model\n",
        "\n",
        "Although we have reached our desired goal in the previous two models, but lets try if we can reduce the parameters further and still maintain the same validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gm53F9Jr_X5",
        "colab_type": "code",
        "outputId": "ae15ed6e-bdae-48b0-b0e9-ceff9034b278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))  # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(2))  # 11\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))  # 3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_113 (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_73 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 24, 24, 10)        910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_74 (Batc (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 22, 22, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_75 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_76 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_77 (Batc (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_78 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_79 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_80 (Batc (None, 3, 3, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_121 (Conv2D)          (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,530\n",
            "Trainable params: 7,358\n",
            "Non-trainable params: 172\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siI2rcmoteh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.01 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JUz6scktktn",
        "colab_type": "code",
        "outputId": "6d40acf9-a99b-4f69-a52e-11fd74706516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=512, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0442 - acc: 0.9864 - val_loss: 0.0334 - val_acc: 0.9898\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0075815011.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0376 - acc: 0.9877 - val_loss: 0.0273 - val_acc: 0.9902\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0061050061.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0317 - acc: 0.9899 - val_loss: 0.0240 - val_acc: 0.9923\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.005109862.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0288 - acc: 0.9906 - val_loss: 0.0201 - val_acc: 0.9938\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0043936731.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0271 - acc: 0.9911 - val_loss: 0.0231 - val_acc: 0.9932\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0038535645.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0246 - val_acc: 0.9920\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.003431709.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0263 - acc: 0.9914 - val_loss: 0.0203 - val_acc: 0.9934\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0030931024.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0248 - acc: 0.9922 - val_loss: 0.0264 - val_acc: 0.9924\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0028153153.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0243 - val_acc: 0.9927\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0025833118.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0250 - acc: 0.9920 - val_loss: 0.0221 - val_acc: 0.9929\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0023866348.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0206 - val_acc: 0.9938\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0022177866.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0213 - val_acc: 0.9939\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.002071251.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0233 - acc: 0.9928 - val_loss: 0.0187 - val_acc: 0.9944\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0019428793.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0195 - val_acc: 0.9940\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0018294914.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 0.0195 - val_acc: 0.9944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d58a4bac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILG5FN1o02XK",
        "colab_type": "text"
      },
      "source": [
        "### We have reached our desired validation accuracy of 99.4% in `Epoch#13` and onwards \n",
        "### We have also learnt that the approaches discussed in the above models is capable in achieving the desired validation accuracy with less than 8000 parameters also."
      ]
    }
  ]
}